{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AfLosUvhcbkR",
        "outputId": "0ba41fdd-3ed7-4115-9a0a-0f14947574ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index-core in /usr/local/lib/python3.12/dist-packages (0.14.7)\n",
            "Requirement already satisfied: llama-index-llms-groq in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (3.13.1)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (1.3.1)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (2.10.3)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (4.5.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (2.11.10)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core) (2.0.44)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (0.12.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (4.15.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (2.0.0)\n",
            "Requirement already satisfied: llama-index-llms-openai-like<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-groq) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core) (1.22.0)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core) (3.1.6)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.7,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (0.6.7)\n",
            "Requirement already satisfied: transformers<5,>=4.37.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (4.57.1)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core) (3.26.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-core) (0.16.0)\n",
            "Requirement already satisfied: openai<2,>=1.108.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-openai<0.7,>=0.6.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (1.109.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.12/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (0.36.0)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (0.6.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->llama-index-core) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core) (3.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (1.2.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.108.1->llama-index-llms-openai<0.7,>=0.6.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.108.1->llama-index-llms-openai<0.7,>=0.6.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (0.11.1)\n",
            "Requirement already satisfied: tavily-python in /usr/local/lib/python3.12/dist-packages (0.7.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from tavily-python) (2.32.4)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tavily-python) (0.12.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from tavily-python) (0.28.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python) (2025.10.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->tavily-python) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->tavily-python) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->tavily-python) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->tavily-python) (4.15.0)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m129.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyngrok\n",
            "  Downloading pyngrok-7.4.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Downloading pyngrok-7.4.1-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index-core llama-index-llms-groq\n",
        "!pip install tavily-python\n",
        "!pip install -q streamlit\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import asyncio\n",
        "import json\n",
        "import textwrap\n",
        "import time\n",
        "import streamlit as st\n",
        "\n",
        "from tavily import AsyncTavilyClient\n",
        "from llama_index.core.workflow import Context\n",
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.core.agent.workflow import (\n",
        "    FunctionAgent,\n",
        "    AgentWorkflow,\n",
        "    AgentInput,\n",
        "    AgentOutput,\n",
        "    ToolCall,\n",
        "    ToolCallResult,\n",
        "    AgentStream,\n",
        ")\n",
        "from llama_index.llms.groq import Groq\n",
        "\n",
        "GROQ_API_KEY = \"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\"\n",
        "TAVILY_API_KEY = \"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\"\n",
        "MODEL_NAME = \"openai/gpt-oss-120b\"   #  llama-3.1-70b-versatile   openai/gpt-oss-120b\n",
        "\n",
        "st.set_page_config(page_title=\"Multi-Agent LinkedIn Blog Writing System\", page_icon=\"‚úçÔ∏è\", layout=\"wide\")\n",
        "st.title(\"‚úçÔ∏è Multi-Agent LinkedIn Blog Writing System\")\n",
        "\n",
        "# Prompt\n",
        "default_prompt = (\n",
        "    \"Write me a blog post on generative AI of about 80 words. \"\n",
        "    \"Briefly describe the history of generative AI and some examples.\"\n",
        ")\n",
        "user_prompt = st.text_area(\"üìù Prompt\", value=default_prompt, height=120)\n",
        "\n",
        "# Layout placeholders\n",
        "col1, col2 = st.columns([1.2, 1])\n",
        "with col1:\n",
        "    log_box = st.empty()          # event log\n",
        "with col2:\n",
        "    notes_box = st.empty()        # research notes\n",
        "    blog_box = st.empty()         # blog markdown\n",
        "    review_box = st.empty()       # review text\n",
        "\n",
        "\n",
        "# Web search tool (async) ‚Äî now with error surfacing\n",
        "async def web_search(query: str, recency_days: int = None, top_n: int = 5, **kwargs) -> str:\n",
        "    \"\"\"Useful for using the web to answer questions.\"\"\"\n",
        "    try:\n",
        "        client = AsyncTavilyClient(api_key=TAVILY_API_KEY)\n",
        "        result = await client.search(query, search_depth=\"basic\", max_results=top_n)\n",
        "        return json.dumps(result, ensure_ascii=False)\n",
        "    except Exception as e:\n",
        "        return f\"ERROR: web_search failed -> {type(e).__name__}: {e}\"\n",
        "\n",
        "# Notes tool (async)\n",
        "async def record_notes(ctx: Context, notes: str, notes_title: str) -> str:\n",
        "    \"\"\"Record notes on a given topic. Provide notes and a title.\"\"\"\n",
        "    try:\n",
        "        async with ctx.store.edit_state() as ctx_state:\n",
        "            if \"research_notes\" not in ctx_state[\"state\"]:\n",
        "                ctx_state[\"state\"][\"research_notes\"] = {}\n",
        "            ctx_state[\"state\"][\"research_notes\"][notes_title] = notes\n",
        "        return \"Notes recorded.\"\n",
        "    except Exception as e:\n",
        "        return f\"ERROR: record_notes failed -> {type(e).__name__}: {e}\"\n",
        "\n",
        "# Blog writer tool (async)\n",
        "async def blog_writer(ctx: Context, blog_content: str) -> str:\n",
        "    \"\"\"Write a markdown blog post on a given topic.\"\"\"\n",
        "    try:\n",
        "        async with ctx.store.edit_state() as ctx_state:\n",
        "            ctx_state[\"state\"][\"blog_content\"] = blog_content\n",
        "        return \"Blog written.\"\n",
        "    except Exception as e:\n",
        "        return f\"ERROR: blog_writer failed -> {type(e).__name__}: {e}\"\n",
        "\n",
        "# Review tool (async)\n",
        "async def review_blog(ctx: Context, review: str) -> str:\n",
        "    \"\"\"Review a blog post and suggest improvements.\"\"\"\n",
        "    try:\n",
        "        async with ctx.store.edit_state() as ctx_state:\n",
        "            ctx_state[\"state\"][\"review\"] = review\n",
        "        return \"Blog reviewed.\"\n",
        "    except Exception as e:\n",
        "        return f\"ERROR: review_blog failed -> {type(e).__name__}: {e}\"\n",
        "\n",
        "def build_tools():\n",
        "    return (\n",
        "        FunctionTool.from_defaults(\n",
        "            fn=web_search,\n",
        "            name=\"web_search_tool\",\n",
        "            description=\"Useful for using the web to answer questions.\",\n",
        "        ),\n",
        "        FunctionTool.from_defaults(\n",
        "            fn=record_notes,\n",
        "            name=\"record_notes_tool\",\n",
        "            description=\"Record notes on a given topic. Provide notes and a title.\",\n",
        "        ),\n",
        "        FunctionTool.from_defaults(\n",
        "            fn=blog_writer,\n",
        "            name=\"write_blog_tool\",\n",
        "            description=\"Write a markdown blog post on a given topic.\",\n",
        "        ),\n",
        "        FunctionTool.from_defaults(\n",
        "            fn=review_blog,\n",
        "            name=\"review_blog_tool\",\n",
        "            description=\"Review a blog post and suggest improvements.\",\n",
        "        ),\n",
        "    )\n",
        "\n",
        "def build_agents(llm, tools):\n",
        "    web_search_tool, record_notes_tool, write_blog_tool, review_blog_tool = tools\n",
        "\n",
        "    research_agent = FunctionAgent(\n",
        "        name=\"ResearchAgent\",\n",
        "        description=\"Search the web for information and record notes.\",\n",
        "        system_prompt=(\n",
        "            \"You are the ResearchAgent that can search the web for information on a given topic and record notes. \"\n",
        "            \"Once notes are recorded and you are satisfied, hand off to the WriteAgent to write the blog post. \"\n",
        "            \"Have at least some notes before handing off.\"\n",
        "        ),\n",
        "        llm=llm,\n",
        "        tools=[web_search_tool, record_notes_tool],\n",
        "        can_handoff_to=[\"WriteAgent\"],\n",
        "    )\n",
        "\n",
        "    write_agent = FunctionAgent(\n",
        "        name=\"WriteAgent\",\n",
        "        description=\"Write a blog post on a given topic.\",\n",
        "        system_prompt=(\n",
        "            \"You are the WriteAgent that writes a blog post in markdown. Ground your writing in the research notes. \"\n",
        "            \"After writing the blog post, you MUST immediately hand off to the ReviewAgent for feedback. \"\n",
        "            \"If the ReviewAgent requests changes, implement them and then hand back for a final review.\"\n",
        "        ),\n",
        "        llm=llm,\n",
        "        tools=[write_blog_tool],\n",
        "        can_handoff_to=[\"ReviewAgent\", \"ResearchAgent\"],\n",
        "    )\n",
        "\n",
        "    review_agent = FunctionAgent(\n",
        "        name=\"ReviewAgent\",\n",
        "        description=\"Review a blog post and suggest improvements.\",\n",
        "        system_prompt=(\n",
        "            \"You are the ReviewAgent that reviews the blog and suggests improvements. \"\n",
        "            \"Write a concise, actionable review. If changes are required, explicitly hand back to the WriteAgent. \"\n",
        "            \"If the post is good to publish, clearly state that it is approved.\"\n",
        "        ),\n",
        "        llm=llm,\n",
        "        tools=[review_blog_tool],\n",
        "        can_handoff_to=[\"WriteAgent\"],\n",
        "    )\n",
        "\n",
        "    return research_agent, write_agent, review_agent\n",
        "\n",
        "def build_workflow(research_agent, write_agent, review_agent):\n",
        "    return AgentWorkflow(\n",
        "        agents=[research_agent, write_agent, review_agent],\n",
        "        root_agent=research_agent.name,\n",
        "        initial_state={\n",
        "            \"research_notes\": {},\n",
        "            \"blog_content\": \"Not written yet.\",\n",
        "            \"review\": \"Review required.\",\n",
        "        },\n",
        "    )\n",
        "\n",
        "\n",
        "async def run_agents_and_stream(prompt: str):\n",
        "    \"\"\"Runs the workflow and streams events to Streamlit placeholders.\"\"\"\n",
        "    llm = Groq(model=MODEL_NAME, api_key=GROQ_API_KEY, additional_kwargs={\"tool_choice\": \"auto\"})\n",
        "    tools = build_tools()\n",
        "    research_agent, write_agent, review_agent = build_agents(llm, tools)\n",
        "    agent_workflow = build_workflow(research_agent, write_agent, review_agent)\n",
        "\n",
        "    latest_notes = {}\n",
        "    latest_blog_md = None\n",
        "    latest_review = None\n",
        "\n",
        "    rolling_text_by_agent = {}\n",
        "\n",
        "    logs = []\n",
        "    current_agent = None\n",
        "\n",
        "    handler = agent_workflow.run(user_msg=prompt)\n",
        "    got_any_event = False\n",
        "\n",
        "    async for event in handler.stream_events():\n",
        "        got_any_event = True\n",
        "\n",
        "        # Agent switch\n",
        "        if hasattr(event, \"current_agent_name\"):\n",
        "            current_agent = event.current_agent_name\n",
        "            logs.append(\"\\n\" + \"=\" * 50)\n",
        "            logs.append(f\"ü§ñ Agent: {current_agent}\")\n",
        "            logs.append(\"=\" * 50 + \"\\n\")\n",
        "            rolling_text_by_agent.setdefault(current_agent, \"\")\n",
        "\n",
        "\n",
        "        if isinstance(event, AgentStream):\n",
        "            if getattr(event, \"delta\", None):\n",
        "                rolling_text_by_agent[current_agent] = rolling_text_by_agent.get(current_agent, \"\") + str(event.delta)\n",
        "                logs.append(f\"‚Ä¶ {textwrap.shorten(str(event.delta), width=140, placeholder=' ‚Ä¶')}\")\n",
        "\n",
        "        elif isinstance(event, AgentOutput):\n",
        "            if event.response and event.response.content:\n",
        "                logs.append(f\"üì§ Output: {event.response.content}\")\n",
        "                rolling_text_by_agent[current_agent] = rolling_text_by_agent.get(current_agent, \"\") + str(event.response.content)\n",
        "                if current_agent == \"ReviewAgent\":\n",
        "                    latest_review = event.response.content\n",
        "            if event.tool_calls:\n",
        "                tools_list = [call.tool_name for call in event.tool_calls]\n",
        "                logs.append(f\"üõ†Ô∏è Planning to use tools: {tools_list}\")\n",
        "\n",
        "        elif isinstance(event, ToolCall):\n",
        "            logs.append(f\"üî® Calling Tool: {event.tool_name}\")\n",
        "            logs.append(f\"  With arguments: {event.tool_kwargs}\")\n",
        "\n",
        "        elif isinstance(event, ToolCallResult):\n",
        "            logs.append(f\"üîß Tool Result ({event.tool_name}):\")\n",
        "            pretty_args = textwrap.shorten(str(event.tool_kwargs), width=500, placeholder=\" ‚Ä¶\")\n",
        "            logs.append(f\"  Arguments: {pretty_args}\")\n",
        "            try:\n",
        "                out_txt = str(event.tool_output)\n",
        "            except Exception as e:\n",
        "                out_txt = f\"<non-stringable output: {type(e).__name__}: {e}>\"\n",
        "            short_out = textwrap.shorten(out_txt, width=800, placeholder=\" ‚Ä¶\")\n",
        "            logs.append(f\"  Output: {short_out}\")\n",
        "\n",
        "\n",
        "            if event.tool_name == \"record_notes_tool\":\n",
        "                try:\n",
        "                    notes = event.tool_kwargs.get(\"notes\", \"\")\n",
        "                    title = event.tool_kwargs.get(\"notes_title\", \"Notes\")\n",
        "                    latest_notes[title] = notes\n",
        "                except Exception:\n",
        "                    pass\n",
        "            elif event.tool_name == \"write_blog_tool\":\n",
        "                latest_blog_md = event.tool_kwargs.get(\"blog_content\", \"\")\n",
        "            elif event.tool_name == \"review_blog_tool\":\n",
        "                latest_review = event.tool_kwargs.get(\"review\", \"\")\n",
        "\n",
        "        log_box.markdown(\"```\\n\" + \"\\n\".join(logs[-200:]) + \"\\n```\")\n",
        "        if latest_notes:\n",
        "            last_title = list(latest_notes.keys())[-1]\n",
        "            notes_box.markdown(f\"### üóíÔ∏è Research Notes ({last_title})\\n\\n```\\n{latest_notes[last_title]}\\n```\")\n",
        "        if latest_blog_md is not None:\n",
        "            blog_box.markdown(\"### üßæ Blog Draft\\n\\n\" + latest_blog_md)\n",
        "        if latest_review is not None:\n",
        "            review_box.markdown(\"### ‚úÖ Review\\n\\n\" + f\"> {latest_review}\")\n",
        "\n",
        "    write_text = rolling_text_by_agent.get(\"WriteAgent\", \"\").strip()\n",
        "    review_text = rolling_text_by_agent.get(\"ReviewAgent\", \"\").strip()\n",
        "\n",
        "    if not latest_review and review_text:\n",
        "        review_box.markdown(\"### ‚úÖ Review (from stream)\\n\\n\" + f\"> {review_text}\")\n",
        "\n",
        "# Run Button\n",
        "if st.button(\"‚ñ∂Ô∏è Run Agents\", type=\"primary\"):\n",
        "    if not user_prompt.strip():\n",
        "        st.error(\"Please enter a prompt to run.\")\n",
        "    else:\n",
        "        # Reset panels\n",
        "        log_box.empty()\n",
        "        notes_box.empty()\n",
        "        blog_box.empty()\n",
        "        review_box.empty()\n",
        "\n",
        "        try:\n",
        "            asyncio.run(run_agents_and_stream(user_prompt.strip()))\n",
        "        except RuntimeError as e:\n",
        "            if \"asyncio.run() cannot be called from a running event loop\" in str(e):\n",
        "                loop = asyncio.get_event_loop()\n",
        "                loop.create_task(run_agents_and_stream(user_prompt.strip()))\n",
        "            else:\n",
        "                st.exception(e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9vGemSedgqi",
        "outputId": "27ac2103-b74d-438e-a264-8a89095ab707"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"34hUYuKYXs52UgRg39TbIiU6DMW_2zrjXbfvRUcNnhTd8gnoi\")\n"
      ],
      "metadata": {
        "id": "xBZchfaddkV9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup streamlit run app.py --server.port 8501 &\n",
        "ngrok_tunnel = ngrok.connect(addr='8501', proto='http', bind_tls=True)\n",
        "print(' * Tunnel URL:', ngrok_tunnel.public_url)"
      ],
      "metadata": {
        "id": "Qu8x-99ieR61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c1d81b5-8904-42db-a189-ca0039acc94e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            " * Tunnel URL: https://centauric-hymnological-maegan.ngrok-free.dev\n"
          ]
        }
      ]
    }
  ]
}